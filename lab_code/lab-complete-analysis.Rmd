---
title: 'Lab 9: Analysis Pipeline'
author: "Esa Schenck"
date: '2022-07-01'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Goal: by the end of this lab you will understand how to use the skills we've developed so far to perform exploratory data analysis. 

# Setting Up 
Let's load the packages we're going to use in this lab.
```{r}
library(tidyverse)
library(ggplot2)
```

# Part 1: Looking through different datasets

Part of what exploratory data analysis is to look through several different datasets, begin to formulate big-picture questions, and see if or how we can answer those questions using the datasets.

All of the following data is from {r}[gapminder.org](https://www.gapminder.org/data/), which you also saw in Lab 5. Feel free to try out this process on your own with different data, either from the same site or another source!

Often, before we start working with a specific dataset, we have a big, high-level question or topic we are interested in. Let's start this lab by saying *we want to make comparisons about countries*. The following parts of this lab start to investigate this high-level topic with different datasets.  

## Dataset 1: Proportion of people who disagree that vaccines are effective

### Step 1: Read the description

The Gapminder description of these data is that "This is the proportion of people who **disagree** that vaccines are effective for children to have." 

I added the emphasis, because it's important to be clear what the statement is saying. Note that the rest of the population might not *agree* that vaccines are effective for children to have, because they could be undecided on the question. We don't know!

### Step 2: Load and look at the data!

Note that you might have a different filepath than I do, so change the code here as needed!
```{r}
vaccine <- read_csv("SSEP_Data/vccin_effect_dag.csv")

head(vaccine)
```

Right away, take a moment to notice that this isn't tidy data. When we want to analyze or graph it, we'll need to `pivot_wider()` first. Here's a challenge: Can you explain why this isn't tidy and why we need to pivot?

Also, I notice something odd... looking at the data, there are columns for every year from 2014 to 2017, but so far I only see NA values for 2015 and 2016. We might have a better idea of the data if we used `summary()`.

```{r}
summary(vaccine)
```

Okay! The summary gives us more information. Here are my immediate thoughts:

 - Both 2015 and 2016 say "Mode:logical, NA's:146". This means that there is *no* data for 2015 or 2016. In other words, we only have real data for 2014 and 2017.
 - Both 2014 and 2017 have some NA values, but there are more NA's in 2014 (78) than 2017 (4).
 - I'm noticing that in 2014 there was a global minimum of 0% disagreement in vaccine efficacy but in 2017 there was a minimum 0.4% disagreement. Similarly, the maximum disagreement rose from 26% to 27.6%. I wonder if that means that global disagreement rose from 2014 to 2017, or if that was just one or two outliers skewing the data.
 - Now that I'm thinking about outliers, I notice that the 3rd quartile of 2017 is 7.7%, while the maximum value is 27.6%. I wonder if that means that the majority of countries have little disagreement with vaccine efficacy, but only a few (or even only one or two) countries disagrees very strongly.
 
Can you make any more observations -- or even think of some more questions -- based on what we see in the data so far? Once you're done, we'll move on to the next step!

### Step 3: Start asking questions

Right away, I see two possible routes we could go (remember, we're interested in comparing different countries to each other or comparing the same country over years).

Here, that means comparing how many people disagree with vaccine efficacy across different countries (e.g., how many people disagree with vaccine efficacy in Afghanistan versus Albania), **and/or** how many people disagree with vaccine efficacy in the same country over time (e.g. in Afghanistan in 2014 vs. Afghanistan in 2017).

I remember that, looking at the data, we only have two years of data, so maybe just asking "how did one country change over time" isn't so interesting. For example, let's look at a quick scatter plot I can make of Afghanistan's change in vaccine disagreement.

```{r}
vaccine %>% 
  filter(country == "Afghanistan") %>% 
  pivot_longer(cols = -country,
               names_to = "year", 
               values_to = "disagreement") %>% 
  ggplot(aes(x = year, y = disagreement)) +
  geom_point()
```

Well, it looks like disagreement with vaccine efficacy went down in Afghanistan between 2014 and 2017, but that's a pretty boring graph, huh?

Maybe you can come up with some more interesting questions to explore! Feel free to look at the data some more and make a couple graphs. As for me, I'm not so interested in this dataset: there aren't very many questions we could explore, since there is so little data to work with.

**That's why, in the early stages of an investigation, it can be important to look through multiple datasets until you find one you want to work with!**


## Dataset 2: Ratio girls/boys in school, primary and secondary education (%)

### Step 1: Read the description

This dataset's description is "Gender parity index for gross enrollment ratio in primary and secondary education is the ratio of girls to boys enrolled at primary and secondary levils in public and private schools."

I don't know about you, but I'm grateful that they defined "gender parity index for gross enrollment ratio..." -- that's a complicated phrase!

Taking a guess, since the ratio is of girls:boys, I would want (in an ideal world) the number for each country to be as close to 1 as possible. That would mean an equal number of girls as boys are receiving an education and are not hindered by sexism.

However, knowing the state of the world, I expect that many numbers are going to be less than 1 (or even approaching 0), since in many cases fewer girls get to go to school than boys,

### Step 2: Load and look at the data

Usually, after loading the data, this means using `glimpse()` or `head()` to get an idea of what the columns and rows look like and then using `summary()` to get a basic idea of the spread of the data.

```{r}
school <- read_csv("SSEP_Data/ratio_of_girls_to_boys_in_primary_and_secondary_education_perc.csv")

head(school)
```
So, looking at these data, I notice again that we're not working with tidy data. That's good to know for the future! 

I also notice that the data begin in 1969 and end in 2020, so we're covering a much wider time period than the previous dataset did.

Can you make any other observations about the data that might be useful going forward?

```{r}
summary(school)
```

Wow! That summary is long -- probably because there are so many years covered here. (This is another reason why we might want to pivot.) I don't know about you, but I like my summaries to be shorter than this. Instead of reading it all, I'm going to pivot the dataframe now and then run another summary.

```{r}
school <- school %>% 
  pivot_longer(cols = -country, 
               names_to = "year",
               values_to = "ratio") %>% 
  mutate(year = as.numeric(year))
```

```{r}
summary(school)
```

As we knew from seeing the dataframe, the years begin in 1969 and go to 2020. Luckily I'm not seeing any NA's for years! 

The most interesting observations come from the ratio column. First of all, there are 4,899 NA values, which feels like a lot. We might have to deal with those when we go to work with the data. Next, I notice that the ratios go from 0 (meaning that 0% of girls attend school in the country) to 1.45 (meaning that more girls than boys attend school). The , 1st quartile, median, mean are all over 0.9, so there is near-gender equality in schooling worldwide, but the median is higher than the mean, so that mean is probably brought down by several countries that have very few or no girls in school.

Do you have any other observations to add? Is there anything that surprised you about the data we've looked at so far?

### Step 3: Start asking questions

Since we noticed in the last step that worldwide there's a mostly equal gender ratio, but that some countries have a very low gender ratio, we might start by asking which countries those are. We could also ask how gender equality has changed over time, since there are so many years in our sample. Maybe those low ratios are all from several decades ago -- or maybe some countries still have very low school ratios.

Let's start by asking how gender equality in eduaction has changed over time.

```{r}
school %>% 
  ggplot(aes(x = year, 
             y = ratio,
             group = country)) +
  geom_line()
```

That's interesting! It seems like some countries have always had fairly steady gender ratios (as seen by that thick black line in the middle), while some countries' gender ratios have historically been lower but are mostly now trending upwards. One country in particular seems to have had mostly girls in school, and is the only country to approaching gender equality from the "other end".

Let's say we're interested in the countries with lower ratios. We can look at which countries have had the lowest ratios, and seeing how only those countries' ratios have changed over time.

How do you think we can do that? We need to:
 - Find the countries with the lowest ratios
 - Filter only for those countries
 - Make the same graph
 
I would approach this topic by using `group_by()` and `mutate()` to find the average gender ratio for each country, and then filter for the lowest ratios -- let's say the lowest 10 countries.

```{r}
#Step 1: Find average ratio of each country
school_low <- school %>%
  group_by(country) %>% 
  filter(!is.na(ratio)) %>% 
  mutate(average = mean(ratio))
  

#Step 2: Find the cutoff average (the highest average a country can have to be considered a 'low ratio' country)
school_low %>%  group_by(country) %>% 
  summarize(average = mean(average)) %>% 
  arrange(average) %>% 
  head(10)
```

If we scroll to the end of the dataframe of the lowest 10 average ratios, we find Gambia at 0.6041250. That means we're going to use that to filter for countries with an average ratio at or below 0.6041250 for our `school_low` dataframe.

```{r}
school_low <- school_low %>% 
  filter(average <= 0.6041250)

glimpse(school_low)
```

Now that we have this dataframe, let's begin to graph it!

```{r}
school_low %>% 
  ggplot(aes(x = year, 
             y = ratio,
             color = country)) +
  geom_line()
```

Looking at the graph, we see that the majority of these "low ratio" countries have trended upwards between 1969 and 2020. However, Afghanistan is a clear outlier -- and probably the reason why the summary minimum was so low earlier. They trended downwards between about 1992 and 2000. Now, we could have background knowledge that might answer the question, "Why did the ratio of girls to boys in school fall so sharply in Afghanistan between those years?" (For example, we could know about the Afghan Civil War from 1992 to '96 and the rise of the Taliban.) However, we might not have access to that kind of background information. That would be where we could start using other datasets to answer questions brought up with our data.

# Part 2: Using multiple datasets

We want to answer the question, *"Why did the ratio of girls to boys in school fall so sharply in Afghanistan between those years?"* Gapminder has a lot of data about different countries. Let's try to brainstorm now about things that might affect girls in school, so that we can try to find data that might answer our question.

Here are some things I came up with:
 - Gender equality in society
 - Young mothers (who might not be able to go to school)
 - Poor economy, war, natural disasters that mean kids *can't* go to school 
 - Population -- maybe there just ARE fewer girls than boys, for whatever reason!
 
**Write down anything else you can come up with!** The key to this list is that it's not formal, nor are we sure that there ARE data to address all of these ideas. We're just brainstorming for possibilities.

Now, we can take a look at gapminder (or another data source) and see if there are any data that match the "hypotheses" we've come up with. Right away, I see that gapminder has several sex ratio datasets and a gdp per capita dataset. While I don't see data about teen or young mothers, I do see "Age at 1st marriage (women)", whihc might be helpful.

I'm going to choose the Age at 1st marriage and GDP per capita datasets, but you don't have to do the same! Feel free to choose another dataset that you think might be helpful and follow along!

## First look at the new data

First thing's first: let's go through the same steps as earlier to take a look at our datasets. Since we already have a question in mind, we can skip "Step 3: Start asking questions".

### Dataset 3: Age at 1st marriage (women)

#### Step 1: Read the description
 
Description from gapminder: "The mean age, in years, of first marriage for women. Women who never married are excluded. Cohabitation is excluded. The data are based on multipe sources and definitions may vary."

That seems pretty straightforward! Let's take a look.

#### Step 2: Load and look at the data

```{r}
marriage <- read_csv("SSEP_Data/age_at_1st_marriage_women.csv")

head(marriage)
```

Right away, I notice that Afghanistan is there (phew!) but so are many other countries. Since at this point we're focusing on Afghanistan, I'm going to filter out every other country. Additionally, the years start at 1615, but the school data we have only starts at 1969. Let's pivot this data, and then filter for year and Afghanistan.

[Question: Why should we pivot the data first?]

```{r}
marriage <- marriage %>% 
  pivot_longer(cols = -country,
               names_to = "year",
               values_to = "marriage") %>% 
  filter(country == "Afghanistan",
         year >= 1969)

head(marriage)
```

Uh-oh! It looks like we have a bunch of empty data for Afghanistan. Since we're only looking at the first six rows, I wonder if there's much data after 1974 or if there won't be enough data to use it at all.

To get a better picture, let's use `summary()`.

```{r}
summary(marriage)
```

Looking at the summary, there are 36 total years and 34 NA's. One of the problems with our earlier dataset was also that there weren't enough years to make a good assessment.

#### Conclusions

Sometimes a dataset doesn't work out -- and that's okay! Part of being a data scientist is knowing when to move on. We do this exploratory work because *not every dataset is perfect for our analysis*, and we want to figure that out early on, before we get invested in the data.

### Dataset 4: GDP/capita (US$, inflation-adjusted)

#### Description

"GDP per capita is gross domestic product divided by midyear population. GDP is the sum of gross value added by all resident producers in teh economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in constant 2010 U.S. dollars."

Wow! That's a lot, and might be confusing. Here's my short version: GDP per capita can be a good indicator of the economic situation of a country, since it measures the country's wealth per person. {r}[Here's](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(PPP)_per_capita) the wikipedia page on the topic if you want to read more.

#### Load and look at the data

```{r}
gdp <- read_csv("SSEP_Data/gdppercapita_us_inflation_adjusted.csv")

head(gdp)
```

Again, let's pivot and filter for Afghanistan after 1969.

```{r}
gdp <- gdp %>% 
  pivot_longer(cols = -country,
               names_to = "year",
               values_to = "gdp") %>% 
  filter(country == "Afghanistan",
         year >= 1969) %>% 
  mutate(year = as.numeric(year))

head(gdp)
```

I don't like where this is going, because the first few rows are NA. Let's see if there is usable data by filtering out NA values and seeing what remains!

```{r}
gdp %>% 
  filter(!is.na(gdp))
```

Okay! It looks like the values for GDP start in 2001 and go until 2019, which gives us 19 years of data to work with. It's not as much as we might have hoped for, but let's move on.

## Combining datasets

Do you remember how to join data? Take a moment to look up a refresher if needed.

For this dataset, we need to combine `school` values for Afghanistan with `gdp` (which now contains only Afghanistan).

```{r}
school <- school %>% 
  filter(country == "Afghanistan") 

afghanistan <- school %>% 
  left_join(gdp, by = c("country", "year")) %>% 
  filter(!is.na(gdp),
         !is.na(ratio))
  

head(afghanistan)
```

This leaves us with data from 2002 to 2019, since the gender ratio data from 2001 was NA. Finally, we can look at whether Afghanistan's GDP may be related to its school gender ratio.

Note that we can't yet say that GDP *caused* the gender ratio -- to do that, we need to use statistics to prove that one caused the other. You might know the phrase: "Correlation, not causation."

```{r}
afghanistan %>% 
  ggplot(aes(x = gdp,
             y = ratio)) +
  geom_point()
```

Looking at the graph, we can say that as GDP increases in Afghanistan, the ratio of girls to boys in school seems to increase as well.